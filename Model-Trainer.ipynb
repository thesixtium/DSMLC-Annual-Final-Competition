{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c23e0a2c",
   "metadata": {},
   "source": [
    "# DSMLC Annual Final Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6ee97e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "524cb713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcdabfa",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "0f54527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # The columns we will make\n",
    "    column_names = ['Year', 'Country', 'Happiness', 'Economy', 'Health', 'Freedom', 'Generosity', 'Corruption']\n",
    "    main_dataframe = pd.DataFrame(columns=column_names)\n",
    "    \n",
    "    # Import xls sheet\n",
    "    xls = pd.ExcelFile('World Happiness Datasets (2015-2022).xlsx')\n",
    "    \n",
    "    for i in range(2015, 2023):\n",
    "        # Read Dataframe In\n",
    "        dataframe = pd.read_excel(xls, f'{i}')\n",
    "        \n",
    "        # Read in year\n",
    "        year = [i for _ in dataframe[dataframe.columns[0]]]\n",
    "        dataframe['Year'] = year\n",
    "        \n",
    "        # Get Old Columns\n",
    "        old_columns = []\n",
    "        if i == 2015 or i == 2016:\n",
    "            old_columns = ['Year', 'Country','Happiness Score', 'Economy (GDP per Capita)', 'Health (Life Expectancy)', 'Freedom', 'Generosity', 'Trust (Government Corruption)']\n",
    "        elif i == 2017:\n",
    "            old_columns = ['Year', 'Country','Happiness.Score', 'Economy..GDP.per.Capita.', 'Health..Life.Expectancy.', 'Freedom', 'Generosity', 'Trust..Government.Corruption.']\n",
    "        elif i == 2018 or i == 2019:\n",
    "            old_columns = ['Year', 'Country or region','Score', 'GDP per capita', 'Healthy life expectancy', 'Freedom to make life choices', 'Generosity', 'Perceptions of corruption']\n",
    "        elif i == 2020 or i == 2021:\n",
    "            old_columns = ['Year', 'Country name','Ladder score', 'Explained by: Log GDP per capita', 'Explained by: Healthy life expectancy', 'Explained by: Freedom to make life choices', 'Explained by: Generosity', 'Explained by: Perceptions of corruption']\n",
    "        else:\n",
    "            old_columns = ['Year', 'Country','Happiness score', 'Explained by: GDP per capita', 'Explained by: Healthy life expectancy', 'Explained by: Freedom to make life choices', 'Explained by: Generosity', 'Explained by: Perceptions of corruption']\n",
    "        \n",
    "        # Get Only Needed Columns\n",
    "        dataframe = dataframe.filter(old_columns)\n",
    "        \n",
    "        # Rename Columns\n",
    "        for column in range(len(column_names)):\n",
    "            dataframe = dataframe.rename(columns={\n",
    "                old_columns[column]: column_names[column]\n",
    "            })\n",
    "        \n",
    "        # Modify needed columns\n",
    "        if i == 2018:\n",
    "            dataframe['Economy'] = dataframe['Economy'].apply(lambda x: x/1000)\n",
    "            dataframe['Happiness'] = dataframe['Happiness'].apply(lambda x: x/1000)\n",
    "        np.seterr(divide = 'ignore') \n",
    "        if i != 2020 and i != 2021:\n",
    "            dataframe['Economy'] = np.log10(dataframe['Economy'])\n",
    "        np.seterr(divide = 'warn') \n",
    "        \n",
    "        # Add dataframe to main dataframe\n",
    "        main_dataframe = pd.concat([main_dataframe, dataframe])\n",
    "    \n",
    "    # Replace inf and -inf with NaN, then Imputer all NaN's\n",
    "    main_dataframe = main_dataframe.replace([np.inf, -np.inf], np.NaN)\n",
    "    main_dataframe = main_dataframe.fillna(main_dataframe.mean(numeric_only=True))\n",
    "    \n",
    "    return main_dataframe\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "ce26a920",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8974ea",
   "metadata": {},
   "source": [
    "## Create Test and Training Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "4dffa854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data, test_ratio):\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "e374838a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = split_train_test(all_data, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "ade3044c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "985"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "e7efe276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e83903",
   "metadata": {},
   "source": [
    "## Transformation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "6ca70c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data):\n",
    "    \n",
    "    one_hot_encoder = OneHotEncoder()\n",
    "    data_one_hot = one_hot_encoder.fit_transform(data['Country'].values.reshape(-1,1))\n",
    "    \n",
    "    one_hot_categories = one_hot_encoder.categories_\n",
    "    one_hot_data = data_one_hot.toarray()\n",
    "    \n",
    "    one_hot_dataframe = pd.DataFrame(\n",
    "        data=one_hot_data,\n",
    "        columns=one_hot_categories)\n",
    "    \n",
    "    numberic_data = data.drop(columns=['Country'])\n",
    "    numberic_data_categories = list(numberic_data.columns.values)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('std_scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    all_data_pipelined = pipeline.fit_transform(numberic_data)\n",
    "    \n",
    "    numberic_dataframe = pd.DataFrame(\n",
    "        data=all_data_pipelined,\n",
    "        columns=numberic_data_categories)\n",
    "    \n",
    "    data_prepped = pd.concat([numberic_dataframe, one_hot_dataframe], axis=1)\n",
    "    data_y = data_prepped.filter(['Happiness'])\n",
    "    data_x = data_prepped.drop(columns=['Happiness'])\n",
    "    \n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "087c0fcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_set_x, train_set_y = transform_data(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1916e6",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "adcd494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd561e79",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "511471d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(train_set_x.values, train_set_y.values)\n",
    "\n",
    "models.append({\n",
    "    'model_name': 'Standrd Linear Regression',\n",
    "    'model': lin_reg\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9097454d",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "72f51f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(train_set_x.values, train_set_y.values)\n",
    "\n",
    "models.append({\n",
    "    'model_name': 'Decision Tree Regressor',\n",
    "    'model': tree_reg\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec754e",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "f45549bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(train_set_x.values, train_set_y.values.ravel())\n",
    "\n",
    "models.append({\n",
    "    'model_name': 'Random Forest Regressor',\n",
    "    'model': forest_reg\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15465539",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "5d3c3bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_name, model):\n",
    "    scores = cross_val_score(model, train_set_x.values, train_set_y.values.ravel(),\n",
    "                            scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    \n",
    "    rmse = np.sqrt(-scores)\n",
    "\n",
    "    print(f'###\\t{model_name.upper()}\\t###')\n",
    "    print(f'\\nMean:\\t\\t{scores.mean()}')\n",
    "    print(f'Standard Dev:\\t{scores.std()}')\n",
    "    print(f'Scores:')\n",
    "    for score in scores:\n",
    "        print(f'\\t{score}')\n",
    "    print(f'\\nNon-Normalized\\nError Range:\\t\\t{rmse.mean()}\\nMin Value In Dataset:\\t{min(train_set_y.values)[0]}\\nMax Value In Dataset:\\t{max(train_set_y.values)[0]}')\n",
    "    print(f'\\nNormalized\\nError Range:\\t\\t{(rmse.mean()-min(train_set_y.values)[0])/(max(train_set_y.values)[0] - min(train_set_y.values)[0])}\\nMin Value In Dataset:\\t{(min(train_set_y.values)[0]-min(train_set_y.values)[0])/(max(train_set_y.values)[0] - min(train_set_y.values)[0])}\\nMax Value In Dataset:\\t{(max(train_set_y.values)[0]-min(train_set_y.values)[0])/(max(train_set_y.values)[0] - min(train_set_y.values)[0])}')\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    return (rmse.mean()-min(train_set_y.values)[0])/(max(train_set_y.values)[0] - min(train_set_y.values)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "ec00b731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###\tSTANDRD LINEAR REGRESSION\t###\n",
      "\n",
      "Mean:\t\t-7.81830811950912e+24\n",
      "Standard Dev:\t2.1035839752468996e+25\n",
      "Scores:\n",
      "\t-7.06397172781102e+25\n",
      "\t-1.9875484467152564e+19\n",
      "\t-6.787501804456458e+24\n",
      "\t-2.3554882267471751e+21\n",
      "\t-2.868053745372194e+21\n",
      "\t-4.739500450966682e+23\n",
      "\t-7.998451252246209e+21\n",
      "\t-2.447406475459781e+23\n",
      "\t-2.270868869990607e+22\n",
      "\t-1.2208624731426348e+21\n",
      "\n",
      "Non-Normalized\n",
      "Error Range:\t\t1257479487295.9058\n",
      "Min Value In Dataset:\t-0.36390394009656307\n",
      "Max Value In Dataset:\t3.8681731101662282\n",
      "\n",
      "Normalized\n",
      "Error Range:\t\t297130574978.11536\n",
      "Min Value In Dataset:\t0.0\n",
      "Max Value In Dataset:\t1.0\n",
      "\n",
      "\n",
      "\n",
      "###\tDECISION TREE REGRESSOR\t###\n",
      "\n",
      "Mean:\t\t-0.016698800116425227\n",
      "Standard Dev:\t0.0063359680064615466\n",
      "Scores:\n",
      "\t-0.02330146470489714\n",
      "\t-0.02271901630639875\n",
      "\t-0.024102999528451977\n",
      "\t-0.007039658916661296\n",
      "\t-0.006224842444297995\n",
      "\t-0.013357142064994356\n",
      "\t-0.01788243302956284\n",
      "\t-0.01928866092402705\n",
      "\t-0.011821359120932177\n",
      "\t-0.02125042412402867\n",
      "\n",
      "Non-Normalized\n",
      "Error Range:\t\t0.12641114796534297\n",
      "Min Value In Dataset:\t-0.36390394009656307\n",
      "Max Value In Dataset:\t3.8681731101662282\n",
      "\n",
      "Normalized\n",
      "Error Range:\t\t0.11585684339831663\n",
      "Min Value In Dataset:\t0.0\n",
      "Max Value In Dataset:\t1.0\n",
      "\n",
      "\n",
      "\n",
      "###\tRANDOM FOREST REGRESSOR\t###\n",
      "\n",
      "Mean:\t\t-0.010311316280739094\n",
      "Standard Dev:\t0.004355693779738279\n",
      "Scores:\n",
      "\t-0.01303403728352392\n",
      "\t-0.015533228029551824\n",
      "\t-0.010004456253633326\n",
      "\t-0.003786447723870612\n",
      "\t-0.009323524067150198\n",
      "\t-0.010125692961040692\n",
      "\t-0.017213611510747906\n",
      "\t-0.01339492558475502\n",
      "\t-0.003774801367281603\n",
      "\t-0.006922438025835837\n",
      "\n",
      "Non-Normalized\n",
      "Error Range:\t\t0.09891180810927051\n",
      "Min Value In Dataset:\t-0.36390394009656307\n",
      "Max Value In Dataset:\t3.8681731101662282\n",
      "\n",
      "Normalized\n",
      "Error Range:\t\t0.10935900804950963\n",
      "Min Value In Dataset:\t0.0\n",
      "Max Value In Dataset:\t1.0\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for model in models:\n",
    "    results.append({\n",
    "        'model': model['model'],\n",
    "        'model_name': model['model_name'],\n",
    "        'result': evaluate_model(model['model_name'], model['model'])\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "14686574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standrd Linear Regression:\t297130574978.11536\n",
      "Decision Tree Regressor:\t0.11585684339831663\n",
      "Random Forest Regressor:\t0.10935900804950963\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(f'{result[\"model_name\"]}:\\t{result[\"result\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1a59a4",
   "metadata": {},
   "source": [
    "## Save Good Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f75c14",
   "metadata": {},
   "source": [
    "### Refresh Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "3edb6eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing Decision Tree Regressor.pkl\n",
      "Removing Random Forest Regressor.pkl\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir()\n",
    "\n",
    "for item in files:\n",
    "    if item.endswith(\".pkl\"):\n",
    "        print(f'Removing {item}')\n",
    "        os.remove(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef68731d",
   "metadata": {},
   "source": [
    "### Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "3e4bbc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not saving Standrd Linear Regression\n",
      "Saving model Decision Tree Regressor as Decision Tree Regressor.pkl\n",
      "Saving model Random Forest Regressor as Random Forest Regressor.pkl\n"
     ]
    }
   ],
   "source": [
    "average_model_accuracy = 0\n",
    "count = 0\n",
    "\n",
    "for model in results:\n",
    "    average_model_accuracy += model[\"result\"]\n",
    "    count += 1\n",
    "\n",
    "average_model_accuracy /= count\n",
    "\n",
    "for model in results:\n",
    "    if model[\"result\"] < average_model_accuracy:\n",
    "        print(f'Saving model {model[\"model_name\"]} as {model[\"model_name\"]}.pkl')\n",
    "        joblib.dump(model['model'], f'{model[\"model_name\"]}.pkl')\n",
    "    else:\n",
    "        print(f'Not saving {model[\"model_name\"]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
